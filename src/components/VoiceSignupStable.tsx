import React, { useEffect, useRef, useState } from "react";

/**
 * âœ… ì•ˆì •í™” í¬ì¸íŠ¸
 * - ë§ˆì´í¬ ê¶Œí•œ ì²´í¬ ë° ì¹œì ˆí•œ ê°€ì´ë“œ
 * - HTTPS/ì˜¤í”„ë¼ì¸/ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ì‚¬ì „ ì ê²€
 * - WebAudio ê¸°ë°˜ ê°„ë‹¨ VAD(ìŒì„±í™œì„±ê°ì§€): RMS ê¸°ì¤€ìœ¼ë¡œ ë§ì†Œë¦¬ ê°ì§€ ì‹œì—ë§Œ STT ì‹œì‘
 * - SpeechRecognition ì˜ˆì™¸( no-speech / not-allowed / network / ë“± )ë³„ ì²˜ë¦¬
 * - onend / onerror ì‹œ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„, ìµœëŒ€ íšŸìˆ˜)
 * - í´ë¦°ì—…(ë§ˆì´í¬/ì˜¤ë””ì˜¤ë…¸ë“œ/recognition) ì² ì €
 *
 * ì‚¬ìš©ë²•:
 * 1) ì´ íŒŒì¼ì„ src/components/VoiceSignupStable.tsx ë¡œ ì €ì¥
 * 2) í˜ì´ì§€ì—ì„œ <VoiceSignupStable /> ë¡œ ë Œë”ë§
 */

type RecognitionLike = SpeechRecognition & {
  // ì¼ë¶€ ë¸Œë¼ìš°ì €ëŠ” webkitSpeechRecognition ë§Œ ì œê³µ
};

const getRecognition = (): RecognitionLike | null => {
  const W = window as any;
  const SR = W.SpeechRecognition || W.webkitSpeechRecognition;
  if (!SR) return null;
  return new SR();
};

const supportsMedia = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);

const HTTPS_REQUIRED_MESSAGE =
  "ë§ˆì´í¬ ì‚¬ìš©ì„ ìœ„í•´ HTTPSê°€ í•„ìš”í•©ë‹ˆë‹¤. ë¡œì»¬ ê°œë°œì€ https://localhost ë¡œ ì‹¤í–‰í•˜ê±°ë‚˜, ë°°í¬ í™˜ê²½ì—ì„œ httpsë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.";
const PERMISSION_MESSAGE =
  "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ìƒë‹¨ ì£¼ì†Œì°½ì˜ ê¶Œí•œ ì„¤ì •ì—ì„œ ë§ˆì´í¬ ì ‘ê·¼ì„ í—ˆìš©í•´ ì£¼ì„¸ìš”.";
const UNSUPPORTED_MESSAGE =
  "ì´ ë¸Œë¼ìš°ì €ëŠ” Web Speech APIë¥¼ ì™„ì „íˆ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Chrome ìµœì‹  ë²„ì „ì„ ê¶Œì¥í•©ë‹ˆë‹¤.";

const VoiceSignupStable: React.FC = () => {
  // UI ìƒíƒœ
  const [ready, setReady] = useState(false);
  const [status, setStatus] = useState<"idle" | "listening" | "waiting" | "error">("idle");
  const [hint, setHint] = useState<string>("");
  const [transcript, setTranscript] = useState<string>("");
  const [lastError, setLastError] = useState<string>("");

  // ì˜¤ë””ì˜¤ & ì¸ì‹ ê°ì²´
  const audioCtxRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const rafIdRef = useRef<number | null>(null);

  const recognitionRef = useRef<RecognitionLike | null>(null);
  const waitingForSpeechRef = useRef<boolean>(false);

  // ì¬ì‹œë„ ê´€ë¦¬
  const attemptRef = useRef<number>(0);
  const maxAttempts = 4; // í•„ìš” ì‹œ ì¡°ì •
  const baseBackoffMs = 800;

  // VAD íŒŒë¼ë¯¸í„° (ê°„ë‹¨ RMS ê¸°ë°˜)
  const RMS_THRESHOLD = 0.035; // ë§ì†Œë¦¬ ì‹œì‘ ì¸ì§€ ê¸°ì¤€ (0~1)
  const SPEECH_HANGOVER_MS = 500; // ë§ ë©ˆì¶˜ ë’¤ ëŒ€ê¸° ì‹œê°„
  const minListenMs = 350; // ë„ˆë¬´ ì§§ì€ ë°œí™” ë°©ì§€

  const vadStateRef = useRef<{
    speaking: boolean;
    lastSpeechTs: number;
    startedAt: number | null;
  }>({ speaking: false, lastSpeechTs: 0, startedAt: null });

  // ì‚¬ì „ ì ê²€
  useEffect(() => {
    (async () => {
      try {
        if (location.protocol !== "https:" && location.hostname !== "localhost") {
          setHint(HTTPS_REQUIRED_MESSAGE);
        }
        if (!navigator.onLine) {
          setHint("ì˜¤í”„ë¼ì¸ ìƒíƒœì…ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.");
        }
        if (!supportsMedia) {
          setHint("ì´ í™˜ê²½ì—ì„œëŠ” ë§ˆì´í¬ ì ‘ê·¼ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
        }
        if (!getRecognition()) {
          setHint((prev) => (prev ? prev + " " : "") + UNSUPPORTED_MESSAGE);
        }

        // ê¶Œí•œ í”„ë¡¬í”„íŠ¸ ìœ ë„ (ì†ŒìŒ ì–µì œ ì˜µì…˜ í¬í•¨)
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          },
        });
        mediaStreamRef.current = stream;

        // ì˜¤ë””ì˜¤ ê·¸ë˜í”„ êµ¬ì„±
        const ctx = new (window.AudioContext || (window as any).webkitAudioContext)();
        audioCtxRef.current = ctx;
        const source = ctx.createMediaStreamSource(stream);
        sourceRef.current = source;

        const analyser = ctx.createAnalyser();
        analyser.fftSize = 1024;
        analyserRef.current = analyser;
        source.connect(analyser);

        setReady(true);
        setHint("ì¤€ë¹„ ì™„ë£Œ. ë§ì†Œë¦¬ë¥¼ ê°ì§€í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤.");
      } catch (e: any) {
        console.error(e);
        setStatus("error");
        if (e && (e.name === "NotAllowedError" || e.name === "SecurityError")) {
          setLastError(PERMISSION_MESSAGE);
        } else {
          setLastError("ë§ˆì´í¬ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: " + (e?.message || e));
        }
      }
    })();

    return () => {
      cleanupAll();
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // VAD ë£¨í”„
  useEffect(() => {
    if (!ready || !analyserRef.current) return;

    const analyser = analyserRef.current;
    const data = new Float32Array(analyser.fftSize);

    const tick = () => {
      analyser.getFloatTimeDomainData(data);
      const rms = computeRMS(data);

      const now = performance.now();
      const vs = vadStateRef.current;

      // speaking íŒì •
      if (!vs.speaking && rms > RMS_THRESHOLD) {
        vs.speaking = true;
        vs.startedAt = now;
        vs.lastSpeechTs = now;
        // ìµœì´ˆ ê°ì§€ ì‹œ STT ì‹œì‘
        maybeStartRecognition();
      } else if (vs.speaking) {
        if (rms > RMS_THRESHOLD) {
          vs.lastSpeechTs = now;
        } else {
          // ë§ ë©ˆì¶¤ ê°ì§€ (hangover)
          if (now - vs.lastSpeechTs > SPEECH_HANGOVER_MS) {
            vs.speaking = false;
            vs.startedAt = null;
            // ì¸ì‹ì€ SpeechRecognitionì´ ì¢…ë£Œ ì´ë²¤íŠ¸ì—ì„œ ë§ˆë¬´ë¦¬
          }
        }
      }

      rafIdRef.current = requestAnimationFrame(tick);
    };

    rafIdRef.current = requestAnimationFrame(tick);
    return () => {
      if (rafIdRef.current) cancelAnimationFrame(rafIdRef.current);
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [ready]);

  const computeRMS = (buf: Float32Array) => {
    let sum = 0;
    for (let i = 0; i < buf.length; i++) {
      const v = buf[i];
      sum += v * v;
    }
    return Math.sqrt(sum / buf.length);
  };

  const maybeStartRecognition = () => {
    if (status === "listening" || waitingForSpeechRef.current) return;
    // ë„ˆë¬´ ì§§ì€ ì†ŒìŒ ë°©ì§€
    const vs = vadStateRef.current;
    if (vs.startedAt && performance.now() - vs.startedAt < minListenMs) return;

    startRecognition();
  };

  const startRecognition = () => {
    const rec = getRecognition();
    if (!rec) {
      setStatus("error");
      setLastError("SpeechRecognitionì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome ìµœì‹  ë²„ì „ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.");
      return;
    }

    // ì´ˆê¸°í™”
    setStatus("listening");
    setHint("ë“£ê³  ìˆì–´ìš”â€¦ ë˜ë ·í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”.");
    setLastError("");
    attemptRef.current = 0;

    rec.lang = "ko-KR";
    rec.interimResults = true;
    rec.continuous = false; // ë°œí™” ë‹¨ìœ„ë¡œ ì¢…ë£Œ

    rec.onstart = () => {
      // console.log("recognition start");
    };

    rec.onresult = (event: SpeechRecognitionEvent) => {
      let finalText = "";
      let interimText = "";

      for (let i = 0; i < event.results.length; i++) {
        const res = event.results[i];
        const txt = res[0]?.transcript || "";
        if (res.isFinal) finalText += txt;
        else interimText += txt;
      }

      if (finalText) setTranscript((prev) => (prev ? prev + " " : "") + finalText.trim());
      if (interimText) setHint(`ì¸ì‹ ì¤‘: ${interimText}`);
    };

    rec.onerror = (event: any) => {
      const err = event?.error || "unknown";
      handleRecognitionError(err);
    };

    rec.onend = () => {
      // ê²°ê³¼ ì—†ì´ ëë‚œ ê²½ìš° ì¬ì‹œë„
      if (status === "listening") {
        if (!hint.startsWith("ì¸ì‹ ì¤‘:") && !transcript) {
          scheduleRetry("ë§ì†Œë¦¬ê°€ ê°ì§€ë˜ì—ˆì§€ë§Œ í…ìŠ¤íŠ¸ê°€ ë‚˜ì˜¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
        } else {
          // ì •ìƒ ì¢…ë£Œ í›„ ëŒ€ê¸°
          setStatus("waiting");
          setHint("ëŒ€ê¸° ì¤‘â€¦ ë‹¤ì‹œ ë§í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì‹í•©ë‹ˆë‹¤.");
        }
      }
    };

    recognitionRef.current = rec;
    rec.start();
  };

  const scheduleRetry = (reason: string) => {
    attemptRef.current += 1;
    if (attemptRef.current > maxAttempts) {
      setStatus("error");
      setLastError(`ì¸ì‹ ì‹¤íŒ¨(ì¬ì‹œë„ ì´ˆê³¼): ${reason}`);
      setHint("ì¬ì‹œë„ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.");
      stopRecognition();
      return;
    }
    const delay = baseBackoffMs * Math.pow(2, attemptRef.current - 1);
    setHint(`ë‹¤ì‹œ ì‹œë„ ì¤‘â€¦ (${attemptRef.current}/${maxAttempts}) ì‚¬ìœ : ${reason}`);
    stopRecognition();
    setTimeout(() => {
      if (status !== "error") startRecognition();
    }, delay);
  };

  const handleRecognitionError = (error: string) => {
    // ë¸Œë¼ìš°ì €ë³„ ê³µí†µ ì—ëŸ¬ í•¸ë“¤ë§
    switch (error) {
      case "no-speech":
        scheduleRetry("ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
        break;
      case "audio-capture":
        setStatus("error");
        setLastError("ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.");
        break;
      case "not-allowed":
      case "service-not-allowed":
        setStatus("error");
        setLastError(PERMISSION_MESSAGE);
        break;
      case "network":
        scheduleRetry("ë„¤íŠ¸ì›Œí¬ ë¬¸ì œë¡œ ì¸ì‹ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.");
        break;
      case "aborted":
        // ì‚¬ìš©ìê°€ ìˆ˜ë™ ì •ì§€í•œ ê²½ìš° ë“±
        setStatus("idle");
        setHint("ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.");
        break;
      default:
        scheduleRetry(`ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: ${error}`);
        break;
    }
  };

  const stopRecognition = () => {
    try {
      recognitionRef.current?.stop();
      recognitionRef.current?.abort();
    } catch {}
    recognitionRef.current = null;
  };

  const cleanupAll = () => {
    stopRecognition();

    if (rafIdRef.current) {
      cancelAnimationFrame(rafIdRef.current);
      rafIdRef.current = null;
    }
    if (sourceRef.current) {
      try {
        sourceRef.current.disconnect();
      } catch {}
      sourceRef.current = null;
    }
    if (analyserRef.current) {
      try {
        analyserRef.current.disconnect();
      } catch {}
      analyserRef.current = null;
    }
    if (audioCtxRef.current) {
      try {
        audioCtxRef.current.close();
      } catch {}
      audioCtxRef.current = null;
    }
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((t) => t.stop());
      mediaStreamRef.current = null;
    }
  };

  // UI í•¸ë“¤ëŸ¬
  const handleStart = () => {
    if (!ready) {
      setHint("ì´ˆê¸°í™” ì¤‘ì´ê±°ë‚˜ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ í›„ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.");
      return;
    }
    setTranscript("");
    attemptRef.current = 0;
    setStatus("waiting");
    setHint("ëŒ€ê¸° ì¤‘â€¦ ë§í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì‹í•©ë‹ˆë‹¤.");
    // VADê°€ ë§ì†Œë¦¬ë¥¼ ê°ì§€í•˜ë©´ ìë™ ì‹œì‘ë¨
  };

  const handleStop = () => {
    setStatus("idle");
    setHint("ì¤‘ì§€ë¨.");
    stopRecognition();
  };

  const handleClear = () => {
    setTranscript("");
    setHint("í…ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤. ë§í•˜ë©´ ë‹¤ì‹œ ì¸ì‹í•©ë‹ˆë‹¤.");
  };

  return (
    <div style={styles.wrap}>
      <h2 style={styles.title}>ğŸ¤ ìŒì„± íšŒì›ê°€ì… â€” ì•ˆì •í™” ëª¨ë“œ</h2>

      <div style={styles.badgeRow}>
        <Badge label={ready ? "ë§ˆì´í¬ ì´ˆê¸°í™” OK" : "ë§ˆì´í¬ ì¤€ë¹„ ì¤‘"} ok={ready} />
        <Badge label={navigator.onLine ? "ì˜¨ë¼ì¸" : "ì˜¤í”„ë¼ì¸"} ok={navigator.onLine} />
        <Badge
          label={getRecognition() ? "SpeechRecognition OK" : "SpeechRecognition ë¯¸ì§€ì›"}
          ok={!!getRecognition()}
        />
        <Badge label={location.protocol === "https:" || location.hostname === "localhost" ? "HTTPS/ë¡œì»¬" : "HTTP"} ok={location.protocol === "https:" || location.hostname === "localhost"} />
      </div>

      <div style={styles.controls}>
        <button onClick={handleStart} disabled={!ready || status === "waiting" || status === "listening"} style={styles.btn}>
          ì‹œì‘
        </button>
        <button onClick={handleStop} style={styles.btn}>
          ì¤‘ì§€
        </button>
        <button onClick={handleClear} style={styles.btnGhost}>
          í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
        </button>
      </div>

      <div style={styles.panel}>
        <div style={styles.row}>
          <span style={styles.label}>ìƒíƒœ</span>
          <span style={styles.value}>
            {status === "idle" && "ëŒ€ê¸°"}
            {status === "waiting" && "ë§ì†Œë¦¬ ëŒ€ê¸° ì¤‘"}
            {status === "listening" && "ì¸ì‹ ì¤‘"}
            {status === "error" && "ì˜¤ë¥˜"}
          </span>
        </div>
        {hint && (
          <div style={styles.hint}>
            {hint}
          </div>
        )}
        {lastError && (
          <div style={styles.error}>
            âš ï¸ {lastError}
          </div>
        )}
        <div style={styles.transcript}>
          <div style={styles.tLabel}>ì¸ì‹ ê²°ê³¼</div>
          <div style={styles.tBox}>{transcript || <span style={{ opacity: 0.6 }}>ì•„ì§ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.</span>}</div>
        </div>
      </div>
    </div>
  );
};

const Badge: React.FC<{ label: string; ok: boolean }> = ({ label, ok }) => {
  return (
    <span
      style={{
        padding: "6px 10px",
        borderRadius: 999,
        fontSize: 12,
        background: ok ? "rgba(16,185,129,0.15)" : "rgba(239,68,68,0.15)",
        color: ok ? "#10B981" : "#EF4444",
        border: `1px solid ${ok ? "#10B981" : "#EF4444"}`,
        marginRight: 8,
      }}
    >
      {label}
    </span>
  );
};

// ì¸ë¼ì¸ ìŠ¤íƒ€ì¼(ìƒ˜í”Œ)
const styles: Record<string, React.CSSProperties> = {
  wrap: { maxWidth: 760, margin: "32px auto", padding: 16, fontFamily: "system-ui, -apple-system, Segoe UI, Roboto, Arial" },
  title: { fontSize: 20, marginBottom: 12 },
  badgeRow: { display: "flex", flexWrap: "wrap", gap: 8, marginBottom: 12 },
  controls: { display: "flex", gap: 8, marginBottom: 12 },
  btn: {
    padding: "10px 14px",
    borderRadius: 12,
    border: "1px solid #e5e7eb",
    background: "#111827",
    color: "white",
    cursor: "pointer",
  },
  btnGhost: {
    padding: "10px 14px",
    borderRadius: 12,
    border: "1px solid #e5e7eb",
    background: "transparent",
    color: "#111827",
    cursor: "pointer",
  },
  panel: { border: "1px solid #e5e7eb", borderRadius: 14, padding: 16 },
  row: { display: "flex", justifyContent: "space-between", marginBottom: 8 },
  label: { fontSize: 13, color: "#6b7280" },
  value: { fontSize: 13, fontWeight: 600 },
  hint: { marginTop: 8, fontSize: 13, color: "#374151" },
  error: { marginTop: 8, fontSize: 13, color: "#b91c1c" },
  transcript: { marginTop: 12 },
  tLabel: { fontSize: 12, color: "#6b7280", marginBottom: 6 },
  tBox: {
    minHeight: 90,
    border: "1px dashed #cbd5e1",
    borderRadius: 10,
    padding: 12,
    fontSize: 14,
    lineHeight: 1.55,
    whiteSpace: "pre-wrap",
  },
};

export default VoiceSignupStable;
