import React, { useEffect, useRef, useState } from "react";/** * ???ˆì •???¬ì¸?? * - ë§ˆì´??ê¶Œí•œ ì²´í¬ ë°?ì¹œì ˆ??ê°€?´ë“œ * - HTTPS/?¤í”„?¼ì¸/ë¸Œë¼?°ì? ?¸í™˜???¬ì „ ?ê? * - WebAudio ê¸°ë°˜ ê°„ë‹¨ VAD(?Œì„±?œì„±ê°ì?): RMS ê¸°ì??¼ë¡œ ë§ì†Œë¦?ê°ì? ?œì—ë§?STT ?œì‘ * - SpeechRecognition ?ˆì™¸( no-speech / not-allowed / network / ??)ë³?ì²˜ë¦¬ * - onend / onerror ???¬ì‹œ??(ì§€??ë°±ì˜¤?? ìµœë? ?Ÿìˆ˜) * - ?´ë¦°??ë§ˆì´???¤ë””?¤ë…¸??recognition) ì² ì? * * ?¬ìš©ë²? * 1) ???Œì¼??src/components/VoiceSignupStable.tsx ë¡??€?? * 2) ?˜ì´ì§€?ì„œ <VoiceSignupStable /> ë¡??Œë”ë§? */type RecognitionLike = SpeechRecognition & {  // ?¼ë? ë¸Œë¼?°ì???webkitSpeechRecognition ë§??œê³µ};const getRecognition = (): RecognitionLike | null => {  const W = window as any;  const SR = W.SpeechRecognition || W.webkitSpeechRecognition;  if (!SR) return null;  return new SR();};const supportsMedia = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);const HTTPS_REQUIRED_MESSAGE =  "ë§ˆì´???¬ìš©???„í•´ HTTPSê°€ ?„ìš”?©ë‹ˆ?? ë¡œì»¬ ê°œë°œ?€ https://localhost ë¡??¤í–‰?˜ê±°?? ë°°í¬ ?˜ê²½?ì„œ httpsë¥??¬ìš©?˜ì„¸??";const PERMISSION_MESSAGE =  "ë§ˆì´??ê¶Œí•œ???„ìš”?©ë‹ˆ?? ë¸Œë¼?°ì? ?ë‹¨ ì£¼ì†Œì°½ì˜ ê¶Œí•œ ?¤ì •?ì„œ ë§ˆì´???‘ê·¼???ˆìš©??ì£¼ì„¸??";const UNSUPPORTED_MESSAGE =  "??ë¸Œë¼?°ì???Web Speech APIë¥??„ì „??ì§€?í•˜ì§€ ?Šì„ ???ˆìŠµ?ˆë‹¤. Chrome ìµœì‹  ë²„ì „??ê¶Œì¥?©ë‹ˆ??";const VoiceSignupStable: React.FC = () => {  // UI ?íƒœ  const [ready, setReady] = useState(false);  const [status, setStatus] = useState<"idle" | "listening" | "waiting" | "error">("idle");  const [hint, setHint] = useState<string>("");  const [transcript, setTranscript] = useState<string>("");  const [lastError, setLastError] = useState<string>("");  // ?¤ë””??& ?¸ì‹ ê°ì²´  const audioCtxRef = useRef<AudioContext | null>(null);  const analyserRef = useRef<AnalyserNode | null>(null);  const mediaStreamRef = useRef<MediaStream | null>(null);  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);  const rafIdRef = useRef<number | null>(null);  const recognitionRef = useRef<RecognitionLike | null>(null);  const waitingForSpeechRef = useRef<boolean>(false);  // ?¬ì‹œ??ê´€ë¦?  const attemptRef = useRef<number>(0);  const maxAttempts = 4; // ?„ìš” ??ì¡°ì •  const baseBackoffMs = 800;  // VAD ?Œë¼ë¯¸í„° (ê°„ë‹¨ RMS ê¸°ë°˜)  const RMS_THRESHOLD = 0.035; // ë§ì†Œë¦??œì‘ ?¸ì? ê¸°ì? (0~1)  const SPEECH_HANGOVER_MS = 500; // ë§?ë©ˆì¶˜ ???€ê¸??œê°„  const minListenMs = 350; // ?ˆë¬´ ì§§ì? ë°œí™” ë°©ì?  const vadStateRef = useRef<{    speaking: boolean;    lastSpeechTs: number;    startedAt: number | null;  }>({ speaking: false, lastSpeechTs: 0, startedAt: null });  // ?¬ì „ ?ê?  useEffect(() => {    (async () => {      try {        if (location.protocol !== "https:" && location.hostname !== "localhost") {          setHint(HTTPS_REQUIRED_MESSAGE);        }        if (!navigator.onLine) {          setHint("?¤í”„?¼ì¸ ?íƒœ?…ë‹ˆ?? ?¤íŠ¸?Œí¬ ?°ê²°???•ì¸?˜ì„¸??");        }        if (!supportsMedia) {          setHint("???˜ê²½?ì„œ??ë§ˆì´???‘ê·¼??ì§€?ë˜ì§€ ?ŠìŠµ?ˆë‹¤.");        }        if (!getRecognition()) {          setHint((prev) => (prev ? prev + " " : "") + UNSUPPORTED_MESSAGE);        }        // ê¶Œí•œ ?„ë¡¬?„íŠ¸ ? ë„ (?ŒìŒ ?µì œ ?µì…˜ ?¬í•¨)        const stream = await navigator.mediaDevices.getUserMedia({          audio: {            echoCancellation: true,            noiseSuppression: true,            autoGainControl: true,          },        });        mediaStreamRef.current = stream;        // ?¤ë””??ê·¸ë˜??êµ¬ì„±        const ctx = new (window.AudioContext || (window as any).webkitAudioContext)();        audioCtxRef.current = ctx;        const source = ctx.createMediaStreamSource(stream);        sourceRef.current = source;        const analyser = ctx.createAnalyser();        analyser.fftSize = 1024;        analyserRef.current = analyser;        source.connect(analyser);        setReady(true);        setHint("ì¤€ë¹??„ë£Œ. ë§ì†Œë¦¬ë? ê°ì??˜ë©´ ?ë™?¼ë¡œ ?¸ì‹???œì‘?©ë‹ˆ??");      } catch (e: any) {        console.error(e);        setStatus("error");        if (e && (e.name === "NotAllowedError" || e.name === "SecurityError")) {          setLastError(PERMISSION_MESSAGE);        } else {          setLastError("ë§ˆì´??ì´ˆê¸°??ì¤??¤ë¥˜ê°€ ë°œìƒ?ˆìŠµ?ˆë‹¤: " + (e?.message || e));        }      }    })();    return () => {      cleanupAll();    };    // eslint-disable-next-line react-hooks/exhaustive-deps  }, []);  // VAD ë£¨í”„  useEffect(() => {    if (!ready || !analyserRef.current) return;    const analyser = analyserRef.current;    const data = new Float32Array(analyser.fftSize);    const tick = () => {      analyser.getFloatTimeDomainData(data);      const rms = computeRMS(data);      const now = performance.now();      const vs = vadStateRef.current;      // speaking ?ì •      if (!vs.speaking && rms > RMS_THRESHOLD) {        vs.speaking = true;        vs.startedAt = now;        vs.lastSpeechTs = now;        // ìµœì´ˆ ê°ì? ??STT ?œì‘        maybeStartRecognition();      } else if (vs.speaking) {        if (rms > RMS_THRESHOLD) {          vs.lastSpeechTs = now;        } else {          // ë§?ë©ˆì¶¤ ê°ì? (hangover)          if (now - vs.lastSpeechTs > SPEECH_HANGOVER_MS) {            vs.speaking = false;            vs.startedAt = null;            // ?¸ì‹?€ SpeechRecognition??ì¢…ë£Œ ?´ë²¤?¸ì—??ë§ˆë¬´ë¦?          }        }      }      rafIdRef.current = requestAnimationFrame(tick);    };    rafIdRef.current = requestAnimationFrame(tick);    return () => {      if (rafIdRef.current) cancelAnimationFrame(rafIdRef.current);    };    // eslint-disable-next-line react-hooks/exhaustive-deps  }, [ready]);  const computeRMS = (buf: Float32Array) => {    let sum = 0;    for (let i = 0; i < buf.length; i++) {      const v = buf[i];      sum += v * v;    }    return Math.sqrt(sum / buf.length);  };  const maybeStartRecognition = () => {    if (status === "listening" || waitingForSpeechRef.current) return;    // ?ˆë¬´ ì§§ì? ?ŒìŒ ë°©ì?    const vs = vadStateRef.current;    if (vs.startedAt && performance.now() - vs.startedAt < minListenMs) return;    startRecognition();  };  const startRecognition = () => {    const rec = getRecognition();    if (!rec) {      setStatus("error");      setLastError("SpeechRecognition??ì§€?ë˜ì§€ ?ŠìŠµ?ˆë‹¤. Chrome ìµœì‹  ë²„ì „???¬ìš©??ì£¼ì„¸??");      return;    }    // ì´ˆê¸°??    setStatus("listening");    setHint("?£ê³  ?ˆì–´?”â€??ë ·?˜ê²Œ ë§ì???ì£¼ì„¸??");    setLastError("");    attemptRef.current = 0;    rec.lang = "ko-KR";    rec.interimResults = true;    rec.continuous = false; // ë°œí™” ?¨ìœ„ë¡?ì¢…ë£Œ    rec.onstart = () => {      // console.log("recognition start");    };    rec.onresult = (event: SpeechRecognitionEvent) => {      let finalText = "";      let interimText = "";      for (let i = 0; i < event.results.length; i++) {        const res = event.results[i];        const txt = res[0]?.transcript || "";        if (res.isFinal) finalText += txt;        else interimText += txt;      }      if (finalText) setTranscript((prev) => (prev ? prev + " " : "") + finalText.trim());      if (interimText) setHint(`?¸ì‹ ì¤? ${interimText}`);    };    rec.onerror = (event: any) => {      const err = event?.error || "unknown";      handleRecognitionError(err);    };    rec.onend = () => {      // ê²°ê³¼ ?†ì´ ?ë‚œ ê²½ìš° ?¬ì‹œ??      if (status === "listening") {        if (!hint.startsWith("?¸ì‹ ì¤?") && !transcript) {          scheduleRetry("ë§ì†Œë¦¬ê? ê°ì??˜ì—ˆì§€ë§??ìŠ¤?¸ê? ?˜ì˜¤ì§€ ?Šì•˜?µë‹ˆ??");        } else {          // ?•ìƒ ì¢…ë£Œ ???€ê¸?          setStatus("waiting");          setHint("?€ê¸?ì¤‘â€??¤ì‹œ ë§í•˜ë©??ë™?¼ë¡œ ?¸ì‹?©ë‹ˆ??");        }      }    };    recognitionRef.current = rec;    rec.start();  };  const scheduleRetry = (reason: string) => {    attemptRef.current += 1;    if (attemptRef.current > maxAttempts) {      setStatus("error");      setLastError(`?¸ì‹ ?¤íŒ¨(?¬ì‹œ??ì´ˆê³¼): ${reason}`);      setHint("?¬ì‹œ???œë„ë¥?ì´ˆê³¼?ˆìŠµ?ˆë‹¤. ?¤ì‹œ ?œë„ ë²„íŠ¼???ŒëŸ¬ì£¼ì„¸??");      stopRecognition();      return;    }    const delay = baseBackoffMs * Math.pow(2, attemptRef.current - 1);    setHint(`?¤ì‹œ ?œë„ ì¤‘â€?(${attemptRef.current}/${maxAttempts}) ?¬ìœ : ${reason}`);    stopRecognition();    setTimeout(() => {      if (status !== "error") startRecognition();    }, delay);  };  const handleRecognitionError = (error: string) => {    // ë¸Œë¼?°ì?ë³?ê³µí†µ ?ëŸ¬ ?¸ë“¤ë§?    switch (error) {      case "no-speech":        scheduleRetry("?Œì„±??ê°ì??˜ì? ?Šì•˜?µë‹ˆ??");        break;      case "audio-capture":        setStatus("error");        setLastError("ë§ˆì´?¬ë? ì°¾ì„ ???†ìŠµ?ˆë‹¤. ?¤ë¥¸ ?…ë ¥ ?¥ì¹˜ë¥?? íƒ?˜ê±°??ê¶Œí•œ???•ì¸?˜ì„¸??");        break;      case "not-allowed":      case "service-not-allowed":        setStatus("error");        setLastError(PERMISSION_MESSAGE);        break;      case "network":        scheduleRetry("?¤íŠ¸?Œí¬ ë¬¸ì œë¡??¸ì‹??ì¤‘ë‹¨?˜ì—ˆ?µë‹ˆ??");        break;      case "aborted":        // ?¬ìš©?ê? ?˜ë™ ?•ì???ê²½ìš° ??        setStatus("idle");        setHint("ì¤‘ì??˜ì—ˆ?µë‹ˆ??");        break;      default:        scheduleRetry(`?????†ëŠ” ?¤ë¥˜: ${error}`);        break;    }  };  const stopRecognition = () => {    try {      recognitionRef.current?.stop();      recognitionRef.current?.abort();    } catch {}    recognitionRef.current = null;  };  const cleanupAll = () => {    stopRecognition();    if (rafIdRef.current) {      cancelAnimationFrame(rafIdRef.current);      rafIdRef.current = null;    }    if (sourceRef.current) {      try {        sourceRef.current.disconnect();      } catch {}      sourceRef.current = null;    }    if (analyserRef.current) {      try {        analyserRef.current.disconnect();      } catch {}      analyserRef.current = null;    }    if (audioCtxRef.current) {      try {        audioCtxRef.current.close();      } catch {}      audioCtxRef.current = null;    }    if (mediaStreamRef.current) {      mediaStreamRef.current.getTracks().forEach((t) => t.stop());      mediaStreamRef.current = null;    }  };  // UI ?¸ë“¤??  const handleStart = () => {    if (!ready) {      setHint("ì´ˆê¸°??ì¤‘ì´ê±°ë‚˜ ê¶Œí•œ???†ìŠµ?ˆë‹¤. ?ˆë¡œê³ ì¹¨ ??ê¶Œí•œ???ˆìš©?´ì£¼?¸ìš”.");      return;    }    setTranscript("");    attemptRef.current = 0;    setStatus("waiting");    setHint("?€ê¸?ì¤‘â€?ë§í•˜ë©??ë™?¼ë¡œ ?¸ì‹?©ë‹ˆ??");    // VADê°€ ë§ì†Œë¦¬ë? ê°ì??˜ë©´ ?ë™ ?œì‘??  };  const handleStop = () => {    setStatus("idle");    setHint("ì¤‘ì???");    stopRecognition();  };  const handleClear = () => {    setTranscript("");    setHint("?ìŠ¤?¸ë? ì´ˆê¸°?”í–ˆ?µë‹ˆ?? ë§í•˜ë©??¤ì‹œ ?¸ì‹?©ë‹ˆ??");  };  return (    <div style={styles.wrap}>      <h2 style={styles.title}>?¤ ?Œì„± ?Œì›ê°€?????ˆì •??ëª¨ë“œ</h2>      <div style={styles.badgeRow}>        <Badge label={ready ? "ë§ˆì´??ì´ˆê¸°??OK" : "ë§ˆì´??ì¤€ë¹?ì¤?} ok={ready} />        <Badge label={navigator.onLine ? "?¨ë¼?? : "?¤í”„?¼ì¸"} ok={navigator.onLine} />        <Badge          label={getRecognition() ? "SpeechRecognition OK" : "SpeechRecognition ë¯¸ì???}          ok={!!getRecognition()}        />        <Badge label={location.protocol === "https:" || location.hostname === "localhost" ? "HTTPS/ë¡œì»¬" : "HTTP"} ok={location.protocol === "https:" || location.hostname === "localhost"} />      </div>      <div style={styles.controls}>        <button onClick={handleStart} disabled={!ready || status === "waiting" || status === "listening"} style={styles.btn}>          ?œì‘        </button>        <button onClick={handleStop} style={styles.btn}>          ì¤‘ì?        </button>        <button onClick={handleClear} style={styles.btnGhost}>          ?ìŠ¤??ì´ˆê¸°??        </button>      </div>      <div style={styles.panel}>        <div style={styles.row}>          <span style={styles.label}>?íƒœ</span>          <span style={styles.value}>            {status === "idle" && "?€ê¸?}            {status === "waiting" && "ë§ì†Œë¦??€ê¸?ì¤?}            {status === "listening" && "?¸ì‹ ì¤?}            {status === "error" && "?¤ë¥˜"}          </span>        </div>        {hint && (          <div style={styles.hint}>            {hint}          </div>        )}        {lastError && (          <div style={styles.error}>            ? ï¸ {lastError}          </div>        )}        <div style={styles.transcript}>          <div style={styles.tLabel}>?¸ì‹ ê²°ê³¼</div>          <div style={styles.tBox}>{transcript || <span style={{ opacity: 0.6 }}>?„ì§ ?ìŠ¤?¸ê? ?†ìŠµ?ˆë‹¤.</span>}</div>        </div>      </div>    </div>  );};const Badge: React.FC<{ label: string; ok: boolean }> = ({ label, ok }) => {  return (    <span      style={{        padding: "6px 10px",        borderRadius: 999,        fontSize: 12,        background: ok ? "rgba(16,185,129,0.15)" : "rgba(239,68,68,0.15)",        color: ok ? "#10B981" : "#EF4444",        border: `1px solid ${ok ? "#10B981" : "#EF4444"}`,        marginRight: 8,      }}    >      {label}    </span>  );};// ?¸ë¼???¤í????˜í”Œ)const styles: Record<string, React.CSSProperties> = {  wrap: { maxWidth: 760, margin: "32px auto", padding: 16, fontFamily: "system-ui, -apple-system, Segoe UI, Roboto, Arial" },  title: { fontSize: 20, marginBottom: 12 },  badgeRow: { display: "flex", flexWrap: "wrap", gap: 8, marginBottom: 12 },  controls: { display: "flex", gap: 8, marginBottom: 12 },  btn: {    padding: "10px 14px",    borderRadius: 12,    border: "1px solid #e5e7eb",    background: "#111827",    color: "white",    cursor: "pointer",  },  btnGhost: {    padding: "10px 14px",    borderRadius: 12,    border: "1px solid #e5e7eb",    background: "transparent",    color: "#111827",    cursor: "pointer",  },  panel: { border: "1px solid #e5e7eb", borderRadius: 14, padding: 16 },  row: { display: "flex", justifyContent: "space-between", marginBottom: 8 },  label: { fontSize: 13, color: "#6b7280" },  value: { fontSize: 13, fontWeight: 600 },  hint: { marginTop: 8, fontSize: 13, color: "#374151" },  error: { marginTop: 8, fontSize: 13, color: "#b91c1c" },  transcript: { marginTop: 12 },  tLabel: { fontSize: 12, color: "#6b7280", marginBottom: 6 },  tBox: {    minHeight: 90,    border: "1px dashed #cbd5e1",    borderRadius: 10,    padding: 12,    fontSize: 14,    lineHeight: 1.55,    whiteSpace: "pre-wrap",  },};export default VoiceSignupStable;