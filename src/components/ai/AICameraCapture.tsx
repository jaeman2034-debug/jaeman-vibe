import React, { useState, useRef, useEffect, useCallback } from 'react';

interface AICameraCaptureProps {
  onCapture: (images: File[]) => void;
  onClose: () => void;
}

interface QualityCheck {
  focus: number;      // ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚° (ì„ ëª…ë„)
  brightness: number; // í‰ê·  íœ˜ë„
  stability: number;  // í”ë“¤ë¦¼ ì •ë„
  centering: number;  // í”„ë ˆì„ ì¤‘ì•™ ë°°ì¹˜
  overall: number;    // ì „ì²´ ì ìˆ˜
}

export default function AICameraCapture({ onCapture, onClose }: AICameraCaptureProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  
  const [isCameraOn, setIsCameraOn] = useState(false);
  const [capturedImages, setCapturedImages] = useState<File[]>([]);
  const [currentQuality, setCurrentQuality] = useState<QualityCheck | null>(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [error, setError] = useState<string | null>(null);

  // ì¹´ë©”ë¼ ì‹œì‘
  const startCamera = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: 'environment', // í›„ë©´ ì¹´ë©”ë¼ ìš°ì„ 
          width: { ideal: 1920 },
          height: { ideal: 1080 },
          focusMode: 'continuous'
        }
      });

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        streamRef.current = stream;
        setIsCameraOn(true);
        setError(null);
      }
    } catch (err) {
      console.error('ì¹´ë©”ë¼ ì‹œì‘ ì‹¤íŒ¨:', err);
      setError('ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  }, []);

  // ì¹´ë©”ë¼ ì •ì§€
  const stopCamera = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    setIsCameraOn(false);
  }, []);

  // í’ˆì§ˆ ì²´í¬ (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚° ê¸°ë°˜)
  const checkQuality = useCallback((imageData: ImageData): QualityCheck => {
    const { data, width, height } = imageData;
    
    // ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ ë° ë¼í”Œë¼ì‹œì•ˆ í•„í„° ì ìš©
    let focus = 0;
    let brightness = 0;
    
    // ì¤‘ì•™ ì˜ì—­ë§Œ ë¶„ì„ (ë” ì •í™•í•œ í’ˆì§ˆ ì²´í¬)
    const centerX = Math.floor(width / 2);
    const centerY = Math.floor(height / 2);
    const regionSize = Math.min(width, height) * 0.6;
    
    for (let y = centerY - regionSize/2; y < centerY + regionSize/2; y++) {
      for (let x = centerX - regionSize/2; x < centerX + regionSize/2; x++) {
        if (x > 0 && x < width - 1 && y > 0 && y < height - 1) {
          const idx = (y * width + x) * 4;
          const r = data[idx];
          const g = data[idx + 1];
          const b = data[idx + 2];
          
          // ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
          const gray = 0.299 * r + 0.587 * g + 0.114 * b;
          brightness += gray;
          
          // ë¼í”Œë¼ì‹œì•ˆ í•„í„° (ì„ ëª…ë„ ì¸¡ì •)
          const laplacian = Math.abs(
            gray * 4 - 
            data[idx - 4] - data[idx + 4] - 
            data[(y-1) * width * 4 + x * 4] - 
            data[(y+1) * width * 4 + x * 4]
          );
          focus += laplacian;
        }
      }
    }
    
    const pixelCount = regionSize * regionSize;
    brightness = brightness / pixelCount / 255; // 0-1 ì •ê·œí™”
    focus = focus / pixelCount / 255; // 0-1 ì •ê·œí™”
    
    // ì•ˆì •ì„±ê³¼ ì¤‘ì•™ ë°°ì¹˜ëŠ” í˜„ì¬ êµ¬í˜„ì—ì„œëŠ” ê¸°ë³¸ê°’ (ì‹¤ì œë¡œëŠ” í”„ë ˆì„ ê°„ ë¹„êµ í•„ìš”)
    const stability = 0.8; // ì„ì‹œê°’
    const centering = 0.9; // ì„ì‹œê°’
    
    const overall = (focus * 0.4 + brightness * 0.3 + stability * 0.2 + centering * 0.1);
    
    return { focus, brightness, stability, centering, overall };
  }, []);

  // ì‹¤ì‹œê°„ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
  useEffect(() => {
    if (!isCameraOn || !videoRef.current || !canvasRef.current) return;

    const interval = setInterval(() => {
      if (videoRef.current && canvasRef.current) {
        const canvas = canvasRef.current;
        const ctx = canvas.getContext('2d');
        if (ctx) {
          canvas.width = videoRef.current.videoWidth;
          canvas.height = videoRef.current.videoHeight;
          ctx.drawImage(videoRef.current, 0, 0);
          
          const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
          const quality = checkQuality(imageData);
          setCurrentQuality(quality);
        }
      }
    }, 500); // 500msë§ˆë‹¤ í’ˆì§ˆ ì²´í¬

    return () => clearInterval(interval);
  }, [isCameraOn, checkQuality]);

  // ì´¬ì˜
  const captureImage = useCallback(async () => {
    if (!videoRef.current || !canvasRef.current) return;

    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    canvas.width = videoRef.current.videoWidth;
    canvas.height = videoRef.current.videoHeight;
    ctx.drawImage(videoRef.current, 0, 0);

    // í’ˆì§ˆ ì²´í¬
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const quality = checkQuality(imageData);

    // í’ˆì§ˆì´ ì¢‹ì§€ ì•Šìœ¼ë©´ ê²½ê³ 
    if (quality.overall < 0.6) {
      setError('í’ˆì§ˆì´ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤. ë” ì„ ëª…í•˜ê²Œ ì´¬ì˜í•´ì£¼ì„¸ìš”.');
      return;
    }

    // Canvasë¥¼ Blobìœ¼ë¡œ ë³€í™˜
    canvas.toBlob((blob) => {
      if (blob) {
        const file = new File([blob], `capture_${Date.now()}.webp`, { type: 'image/webp' });
        setCapturedImages(prev => [...prev, file]);
        setError(null);
      }
    }, 'image/webp', 0.9);
  }, [checkQuality]);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ì¹´ë©”ë¼ ì‹œì‘
  useEffect(() => {
    startCamera();
    return () => stopCamera();
  }, [startCamera, stopCamera]);

  // ì´¬ì˜ ì™„ë£Œ
  const handleComplete = () => {
    if (capturedImages.length > 0) {
      onCapture(capturedImages);
    }
  };

  // í’ˆì§ˆ ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ
  const getQualityColor = (score: number) => {
    if (score >= 0.8) return '#10b981'; // green
    if (score >= 0.6) return '#f59e0b'; // yellow
    return '#ef4444'; // red
  };

  return (
    <div className="fixed inset-0 bg-black z-50 flex flex-col">
      {/* í—¤ë” */}
      <div className="bg-black text-white p-4 flex justify-between items-center">
        <button onClick={onClose} className="text-white text-xl">âœ•</button>
        <h2 className="text-lg font-semibold">AI ìƒí’ˆ ì´¬ì˜</h2>
        <button 
          onClick={handleComplete}
          disabled={capturedImages.length === 0}
          className="bg-blue-600 px-4 py-2 rounded disabled:opacity-50"
        >
          ì™„ë£Œ ({capturedImages.length})
        </button>
      </div>

      {/* ì¹´ë©”ë¼ í”„ë¦¬ë·° */}
      <div className="flex-1 relative">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted
          className="w-full h-full object-cover"
        />
        
        {/* ê°€ì´ë“œ ì˜¤ë²„ë ˆì´ */}
        <div className="absolute inset-0 pointer-events-none">
          <div className="border-2 border-white border-dashed m-8 rounded-lg">
            <div className="text-white text-center p-4">
              <div className="text-sm">ìƒí’ˆì„ í”„ë ˆì„ ì•ˆì— ë°°ì¹˜í•˜ì„¸ìš”</div>
              <div className="text-xs opacity-75">ì •ë©´, ì¸¡ë©´, ë¼ë²¨ ê°ë„ë¡œ ì´¬ì˜</div>
            </div>
          </div>
        </div>

        {/* í’ˆì§ˆ í‘œì‹œ */}
        {currentQuality && (
          <div className="absolute top-4 right-4 bg-black bg-opacity-75 text-white p-3 rounded">
            <div className="text-sm font-semibold mb-2">í’ˆì§ˆ ì ìˆ˜</div>
            <div className="space-y-1 text-xs">
              <div>ì„ ëª…ë„: <span style={{color: getQualityColor(currentQuality.focus)}}>
                {Math.round(currentQuality.focus * 100)}%
              </span></div>
              <div>ë°ê¸°: <span style={{color: getQualityColor(currentQuality.brightness)}}>
                {Math.round(currentQuality.brightness * 100)}%
              </span></div>
              <div>ì „ì²´: <span style={{color: getQualityColor(currentQuality.overall)}}>
                {Math.round(currentQuality.overall * 100)}%
              </span></div>
            </div>
          </div>
        )}
      </div>

      {/* ì»¨íŠ¸ë¡¤ */}
      <div className="bg-black p-4">
        <div className="flex justify-center space-x-4">
          <button
            onClick={captureImage}
            disabled={!isCameraOn || isAnalyzing}
            className="bg-red-600 text-white w-16 h-16 rounded-full disabled:opacity-50"
          >
            ğŸ“¸
          </button>
        </div>
        
        {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
        {error && (
          <div className="text-red-400 text-center mt-2 text-sm">
            {error}
          </div>
        )}
        
        {/* ì´¬ì˜ëœ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° */}
        {capturedImages.length > 0 && (
          <div className="mt-4">
            <div className="text-white text-sm mb-2">ì´¬ì˜ëœ ì´ë¯¸ì§€ ({capturedImages.length}/5)</div>
            <div className="flex space-x-2 overflow-x-auto">
              {capturedImages.map((file, index) => (
                <div key={index} className="relative">
                  <img
                    src={URL.createObjectURL(file)}
                    alt={`ì´¬ì˜ ${index + 1}`}
                    className="w-16 h-16 object-cover rounded"
                  />
                  <button
                    onClick={() => setCapturedImages(prev => prev.filter((_, i) => i !== index))}
                    className="absolute -top-2 -right-2 bg-red-600 text-white w-6 h-6 rounded-full text-xs"
                  >
                    Ã—
                  </button>
                </div>
              ))}
            </div>
          </div>
        )}
      </div>

      {/* ìˆ¨ê²¨ì§„ Canvas (í’ˆì§ˆ ì²´í¬ìš©) */}
      <canvas ref={canvasRef} className="hidden" />
    </div>
  );
} 