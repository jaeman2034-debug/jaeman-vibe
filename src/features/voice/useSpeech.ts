// useSpeech.tsimport { useCallback, useEffect, useRef, useState } from "react";import { startSimpleVAD } from "./simple-vad";import { detectSttSupport } from "./sttSupport";// ???ë™ ? ê? ê¸ˆì?const AUTO_STT = false;// VAD ?œì„±???¬ë? (PTTë§????ŒëŠ” falseë¡??¤ì •)const ENABLE_VAD = false; // VAD ?„ì „ ë¹„í™œ?±í™”// (?µì…˜) ?¬ëŸ¬ ì»´í¬?ŒíŠ¸?ì„œ useSpeech()ë¥??¨ë„ VADê°€ ?˜ë‚˜ë§??Œë„ë¡?ëª¨ë“ˆ ?ˆë²¨ ?±ê???let VAD_SINGLETON: null | { stop: () => void } = null;// 1) ?ë‹¨ near imports ?„ë˜???íƒœ ? ì–¸ ì¶”ê?type Thresholds = { noise: number; start: number; stop: number };type Meter = { rms: number; db: number };export function useSpeech() {  const [isListening, setIsListening] = useState(false);  // ??ì¶”ê?: ?„ê³„ê°?ë¯¸í„° ?íƒœ  const [thresholds, setThresholds] = useState<Thresholds | null>(null);  const [meter, setMeter] = useState<Meter>({ rms: 0, db: -Infinity });  // STT ì§€???ì?  const [sttSupport, setSttSupport] = useState<{ok:boolean; reason?:string}>({ ok: true });  // ë²„íŠ¼ ? ê????¨ì¼ ì§„ì‹¤??  const isListeningRef = useRef(false);  // Web Speech API ?¸ìŠ¤?´ìŠ¤  const recogRef = useRef<SpeechRecognition | null>(null);  // PTT ?„ìš© ?Œì„± ?¸ì‹ ?¸ìŠ¤?´ìŠ¤ ref  const recRef = useRef<SpeechRecognition | null>(null);  // VAD ?¸ë“¤(?????´ë??ì„œ ì°¸ì¡°??  const vadRef = useRef<null | { stop: () => void }>(null);  // ?´ë??ì„œ ?„ë ˆ?„ë§ˆ???…ë°?´íŠ¸?˜ëŠ” ?ˆë²¨??refë¡?ë°›ì•˜?¤ê? 100msë§ˆë‹¤ stateë¡?ë°˜ì˜  const levelRef = useRef(0);  // PTT ?ë™ ?¬ì‹œ??ê´€??refs  const pressedRef = useRef(false);  const busyRef = useRef(false);  const restartTimer = useRef<ReturnType<typeof setTimeout> | null>(null);  // ??ì¶”ê?: 100ms ê°„ê²©?¼ë¡œ ë¯¸í„° ?œì‹œ ?…ë°?´íŠ¸  useEffect(() => {    const id = setInterval(() => {      const rms = levelRef.current;      const db = rms > 0 ? 20 * Math.log10(rms) : -Infinity;      setMeter({ rms, db });    }, 100);    return () => clearInterval(id);  }, []);  // ì´ˆê¸° ??ë²ˆë§Œ ì²´í¬  useEffect(() => {    setSttSupport(detectSttSupport());  }, []);  // --- Web Speech ì¤€ë¹?  const makeRecognizer = useCallback((): SpeechRecognition => {    const SR: any =      (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;    if (!SR) {      console.warn("Web Speech API not supported in this browser.");      throw new Error("Web Speech API not supported");    }    const r: SpeechRecognition = new SR();    r.lang = "ko-KR";        // ?„ìš” ?¸ì–´ë¡?ë³€ê²?    r.continuous = true;     // ê¸¸ê²Œ ?£ê¸°    r.interimResults = true; // ì¤‘ê°„ ê²°ê³¼ ?„ìš” ?†ìœ¼ë©?false    r.maxAlternatives = 1;    r.onresult = (ev: SpeechRecognitionEvent) => {      const last = ev.results[ev.results.length - 1];      const text = last[0]?.transcript ?? "";      // TODO: ?¬ê¸°??textë¥??Œì„œ/?íƒœë¡??˜ê¸°?¸ìš”.      console.log("[STT] text:", text);    };    const restart = () => {      if (!pressedRef.current) return;      if (busyRef.current) return;      if (restartTimer.current) clearTimeout(restartTimer.current);      restartTimer.current = setTimeout(() => {        try { r.start(); } catch {}      }, 120); // ì§§ì? backoff    };    r.onerror = (e: any) => {      // 'no-speech'???¬ì‹œ???€??      if (e?.error === "no-speech") restart();    };    r.onend = () => {      // ?¬ìš©?ê? ?¬ì „???„ë¥´ê³??ˆìœ¼ë©??¬ì‹œ??      restart();    };    r.onstart = () => {      // console.log("[STT] onstart");    };    return r;  }, []);  const ensureRecognition = useCallback(() => {    if (recogRef.current) return;    try {      recogRef.current = makeRecognizer();    } catch (e) {      console.warn("Failed to create recognizer:", e);    }  }, [makeRecognizer]);  // --- STT ?œì–´  const startSTT = useCallback(async () => {    if (!sttSupport.ok) {      console.warn("[STT] not supported:", sttSupport.reason);      return;    }    if (isListeningRef.current) return;    ensureRecognition();    if (!recogRef.current) return;    console.log("starting STT...");    try {      recogRef.current.start();      isListeningRef.current = true;      setIsListening(true);    } catch (e) {      console.warn("STT start failed:", e);    }  }, [ensureRecognition, sttSupport]);  const stopSTT = useCallback(async () => {    if (!isListeningRef.current) return;    if (!recogRef.current) return;    console.log("stopping STT...");    try {      recogRef.current.stop();    } catch (e) {      console.warn("STT stop failed:", e);    }    isListeningRef.current = false;    setIsListening(false);  }, []);  // PTT ?„ìš© ?¨ìˆ˜??  const startPTT = useCallback(() => {    if (busyRef.current) return;    busyRef.current = true;    pressedRef.current = true;    if (!recRef.current) {      try {        recRef.current = makeRecognizer();      } catch (e) {        console.warn("Failed to create recognizer for PTT:", e);        busyRef.current = false;        return;      }    }        try {       recRef.current.start();       isListeningRef.current = true;      setIsListening(true);    } catch (e) {      console.warn("PTT start failed:", e);    } finally {       busyRef.current = false;     }  }, [makeRecognizer]);  const stopPTT = useCallback(() => {    if (busyRef.current) return;    busyRef.current = true;    pressedRef.current = false;        if (!recRef.current) {      console.warn('[PTT] stop ignored (no active rec)');      busyRef.current = false;      isListeningRef.current = false;      setIsListening(false);      return;    }        try {       recRef.current.stop();    } catch (e) {      console.warn('[PTT] stop failed', e);    } finally {       recRef.current = null;      busyRef.current = false;     }        if (restartTimer.current) {       clearTimeout(restartTimer.current);       restartTimer.current = null;     }        isListeningRef.current = false;    setIsListening(false);  }, []);  const onMicClick = useCallback(() => {    if (isListeningRef.current) stopSTT();    else startSTT();  }, [startSTT, stopSTT]);  // --- VAD ì´ˆê¸°???•ë§ ??ë²ˆë§Œ)  useEffect(() => {    // VADê°€ ë¹„í™œ?±í™”?˜ì–´ ?ˆìœ¼ë©?ì´ˆê¸°?”í•˜ì§€ ?ŠìŒ    if (!ENABLE_VAD) {      console.log("[VAD] Disabled - PTT mode only");      return;    }    // ?´ë? ?¤ë¥¸ ì»´í¬?ŒíŠ¸?ì„œ ë§Œë“  ?±ê??¤ì´ ?ˆìœ¼ë©?ê·¸ë?ë¡??¬ì‚¬??    if (VAD_SINGLETON) {      vadRef.current = VAD_SINGLETON;      return;    }    let cancelled = false;    startSimpleVAD({      onRms: (r) => { levelRef.current = r; },           // ??ì¶”ê?: ?ˆë²¨ë§?refë¡?ì¶•ì       onReady: (info) => setThresholds(info),            // ??ì¶”ê?: ?„ê³„ê°??˜ì‹       onSpeechStart: () => {        console.log("[VAD] Speech detected");        if (!AUTO_STT) return;              // ?˜ë™ ëª¨ë“œ        if (!isListeningRef.current) startSTT();      },      onSpeechEnd: () => {        console.log("[VAD] Speech ended");        if (!AUTO_STT) return;        if (isListeningRef.current) stopSTT();      },    }).then((v) => {      if (!cancelled) {        vadRef.current = v;        VAD_SINGLETON = v; // ëª¨ë“ˆ ?ˆë²¨ ?±ê???ë³´ê?      }    });    return () => {      cancelled = true;      // ?±ê??¤ì´ë¯€ë¡??¬ê¸°??stop()???¸ì¶œ?˜ì? ?ŠìŒ      // (???„ì—­?ì„œ VAD ?˜ë‚˜ë§?? ì?; ?„ìš”?˜ë©´ Provider ?¨í„´ ê¶Œì¥)    };  }, [startSTT, stopSTT]);  // cleanup: ì»´í¬?ŒíŠ¸ ?¸ë§ˆ?´íŠ¸ ???•ë¦¬  useEffect(() => {    return () => {      try {         recRef.current?.stop();         recogRef.current?.stop();      } catch {}      recRef.current = null;      recogRef.current = null;    };  }, []);  // ??ì¶”ê?: thresholds, meterë¥??¨ê»˜ ë°˜í™˜  return { isListening, onMicClick, startSTT, stopSTT, startPTT, stopPTT, thresholds, meter, sttSupport };} 
