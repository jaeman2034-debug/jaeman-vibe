// src/utils/mic.ts/** ë§ˆì´??ê¶Œí•œ: ?±ê³µ true / ?¤íŒ¨ false */export async function ensureMicPermission(): Promise<boolean> {    try {      const stream = await navigator.mediaDevices.getUserMedia({        audio: {          noiseSuppression: true,          echoCancellation: true,          autoGainControl: true,          channelCount: 1,          sampleRate: 16000        }      });      stream.getTracks().forEach(t => t.stop());      return true;    } catch (err) {      console.error("ë§ˆì´??ê¶Œí•œ ?”ì²­ ?¤íŒ¨:", err);      return false;    }  }    /** ?ˆì „ ?ëŸ¬ ?¸ì¶œ(ì½œë°± ?†ìœ¼ë©?ì½˜ì†”ë§? */  function safeError(onError: ((m: string) => void) | undefined, msg: string) {    console.error(msg);    if (typeof onError === "function") { try { onError(msg); } catch (e) { console.error(e); } }  }    // >>> @MIC_LISTEN_ONCE_P_SIMPLE// === ê²¹ì ??ì°¨ë‹¨???„ì—­ ===let __activeStream: MediaStream | null = null;let __activeAudioCtx: AudioContext | null = null;let __activeRecognition: any | null = null;export function forceKillMic() {  try { __activeRecognition?.stop?.(); } catch {}  __activeRecognition = null;  try { __activeStream?.getTracks?.().forEach(t => t.stop()); } catch {}  __activeStream = null;  try {     if (__activeAudioCtx && __activeAudioCtx.state !== 'closed') {      __activeAudioCtx.close();     }  } catch {}  __activeAudioCtx = null;}/** * ?Œì„±????ë²ˆë§Œ ?£ê³  ?ìŠ¤??ë°˜í™˜ (ê°„ê²°?? * - ê°„ë‹¨?˜ê³  ?ˆì •?ì¸ êµ¬ì¡° * - ìµœì¢… ê²°ê³¼ ?°ì„ , interim ë°±ì—… * - ê²¹ì ??ë°©ì? ?†ì´ ?œìˆ˜ STTë§? */export function listenOnceP(locale="ko-KR", totalTimeout=20000, preSpeechTimeout=8000, resultTimeout=10000){  return new Promise<string>((resolve, reject) => {    const SR:any = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;    if (!SR) return reject(new Error("??ë¸Œë¼?°ì????Œì„± ?¸ì‹??ì§€?í•˜ì§€ ?ŠìŠµ?ˆë‹¤."));    const rec:any = new SR();    rec.lang = locale;    rec.interimResults = true;         // ?”¸ ì¤‘ê°„ ê²°ê³¼??ë°›ê¸°    rec.maxAlternatives = 3;    rec.continuous = false;    let finished = false, gotSpeech = false;    let bestFinal = "", bestInterim = "";    const finish = (fn:()=>void) => { if (finished) return; finished = true;      try { rec.onresult = rec.onerror = rec.onend = rec.onaudiostart = rec.onsoundstart = rec.onspeechstart = null; } catch {}      try { rec.stop(); } catch {}      fn();    };    const tTotal = setTimeout(() => finish(() => reject(new Error("?œê°„ ì´ˆê³¼: ?¸ì‹???„ë£Œ?˜ì? ?Šì•˜?µë‹ˆ??"))), totalTimeout);    let tPre:any, tRes:any;    const clearTimers = ()=>{ clearTimeout(tTotal); clearTimeout(tPre); clearTimeout(tRes); };    const armRes = ()=>{ clearTimeout(tRes); tRes=setTimeout(()=>{      if (!finished) {        const text = bestFinal || bestInterim || "";        if (text) finish(()=>{ clearTimers(); resolve(text); });        else finish(()=>{ clearTimers(); reject(new Error("?¸ì‹??ì¡°ê¸°??ì¢…ë£Œ?˜ì—ˆ?µë‹ˆ??")); });      }    }, resultTimeout); };    const mark = ()=>{ if (!gotSpeech){ gotSpeech = true; armRes(); } };    rec.onaudiostart = mark; rec.onsoundstart = mark; rec.onspeechstart = mark;    tPre = setTimeout(()=>{ if (!gotSpeech) finish(()=>{ clearTimers(); reject(new Error("ë§ì†Œë¦¬ê? ê°ì??˜ì? ?Šì•˜?µë‹ˆ??")); }); }, preSpeechTimeout);    rec.onresult = (e:any) => {      try {        console.log("?” onresult ?´ë²¤??ë°œìƒ!");        console.log("?“Š results:", e.results);                for (let i=e.resultIndex; i<e.results.length; i++){          const r=e.results[i], a=r?.[0];          const t=(a?.transcript||"").trim();          if (!t) continue;          if (r.isFinal) bestFinal = t; else bestInterim = t;        }        if (gotSpeech) armRes();        if (bestFinal) finish(()=>{ clearTimers(); resolve(bestFinal); }); // ìµœì¢… ?¨ë©´ ì¦‰ì‹œ ë°˜í™˜      } catch {}    };    rec.onerror = (e:any) => { finish(()=>{ clearTimers(); reject(new Error(e?.error || "?Œì„± ?¸ì‹ ?¤ë¥˜")); }); };    rec.onend = () => {      console.log("?”š onend ?´ë²¤??ë°œìƒ");      if (!finished) {        const text = bestFinal || bestInterim || "";        if (text) {          console.log("??onend?ì„œ ?ìŠ¤???•ì¸:", text);          finish(()=>{ clearTimers(); resolve(text); });        } else {          console.log("? ï¸ onend?ì„œ ?ìŠ¤???†ìŒ");          finish(()=>{ clearTimers(); reject(new Error("?¸ì‹??ì¡°ê¸°??ì¢…ë£Œ?˜ì—ˆ?µë‹ˆ??")); });        }      }    };    try {       rec.start();       console.log("?¤ SpeechRecognition ?œì‘??);    } catch {       finish(()=> reject(new Error("SpeechRecognition ?œì‘ ?¤íŒ¨")));     }  });}// <<< @MIC_LISTEN_ONCE_P_SIMPLE    /** (?µì…˜) ?°ì† ?¸ì‹???„ìš”?????¬ìš©?????ˆëŠ” ?¬í¼ */  export function startListening(    locale: string,    onResult: (text: string) => void,    onError?: (message: string) => void  ) {    try {      const SR: any = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;      if (!SR) { safeError(onError, "??ë¸Œë¼?°ì????Œì„± ?¸ì‹??ì§€?í•˜ì§€ ?ŠìŠµ?ˆë‹¤. Chrome???¬ìš©??ì£¼ì„¸??"); return () => {}; }        const rec: any = new SR();      rec.lang = locale || "ko-KR";      rec.interimResults = true;      rec.continuous = true;        rec.onresult = (e: any) => {        let acc = "";        for (let i = e.resultIndex; i < e.results.length; i++) {          acc += e.results[i][0].transcript;        }        onResult(acc.trim());      };        rec.onerror = (e: any) => {        const code = e?.error;        let msg = "?Œì„± ?¸ì‹ ?¤ë¥˜ê°€ ë°œìƒ?ˆìŠµ?ˆë‹¤. ?¤ì‹œ ?œë„??ì£¼ì„¸??";        if (code === "not-allowed") msg = "ë§ˆì´??ê¶Œí•œ??ê±°ë??˜ì—ˆ?µë‹ˆ?? ì£¼ì†Œì°??¼ìª½ ?”’?ì„œ '?ˆìš©'?¼ë¡œ ë³€ê²½í•˜?¸ìš”.";        if (code === "audio-capture") msg = "ë§ˆì´???¥ì¹˜ë¥?ì°¾ì„ ???†ìŠµ?ˆë‹¤. OS???…ë ¥ ?¥ì¹˜ë¥??•ì¸?˜ì„¸??";        if (code === "no-speech") msg = "ë§ì†Œë¦¬ê? ê°ì??˜ì? ?Šì•˜?µë‹ˆ?? ì¡°ê¸ˆ ???¬ê²Œ ?ë ·?˜ê²Œ ë§ì???ì£¼ì„¸??";        safeError(onError, msg);      };        rec.start();      return () => { try { rec.stop(); } catch {} };    } catch {      safeError(onError, "startListening ì´ˆê¸°???¤íŒ¨");      return () => {};    }  }  // >>> @MIC_VU_METER/** * ?¤ì‹œê°?ë§ˆì´???ˆë²¨ ë¯¸í„° * - onLevel: 0~1 ?¬ì´ ?…ë ¥ ê°•ë„ ì½œë°±(ì´ˆë‹¹ 30~60?? * - ë°˜í™˜: stop() ?¨ìˆ˜ (?¤íŠ¸ë¦??¤ë””?¤ì»¨?ìŠ¤???•ë¦¬) */export async function startMicLevelMeter(onLevel: (v: number) => void) {  // ?”´ ?¤ë¥¸ ?ìœ  ëª¨ë‘ ì¢…ë£Œ  forceKillMic();  const stream = await navigator.mediaDevices.getUserMedia({    audio: {      noiseSuppression: true,      echoCancellation: true,      autoGainControl: true,      channelCount: 1,      sampleRate: 16000    }  });  __activeStream = stream;  const Ctx: any = (window as any).AudioContext || (window as any).webkitAudioContext;  const ctx = new Ctx();  __activeAudioCtx = ctx;  const src = ctx.createMediaStreamSource(stream);  const analyser = ctx.createAnalyser();  analyser.fftSize = 1024;  const data = new Uint8Array(analyser.frequencyBinCount);  src.connect(analyser);  let raf = 0;  const loop = () => {    analyser.getByteTimeDomainData(data);    // ?Œí˜•??ì¤‘ì•™(128)?ì„œ ?¼ë§ˆ??ë²—ì–´?˜ëŠ”ì§€ë¡??ˆë²¨ ê³„ì‚°    let peak = 0;    for (let i = 0; i < data.length; i++) {      const dev = Math.abs(data[i] - 128) / 128; // 0~1      if (dev > peak) peak = dev;    }    onLevel(Math.min(1, peak * 2)); // ë¯¼ê°???´ì§ ?¬ë¦¼    raf = requestAnimationFrame(loop);  };  loop();  const stop = () => {    cancelAnimationFrame(raf);    try { src.disconnect(); } catch {}    try { analyser.disconnect(); } catch {}    try { stream.getTracks().forEach(t => t.stop()); } catch {}    try { ctx.close(); } catch {}  };  return stop;}// <<< @MIC_VU_METER// === ?”ë²„ê¹…ìš© ?„ì—­ ?¸ì¶œ ===(window as any).debugListenOnceP = listenOnceP;(window as any).debugForceKillMic = forceKillMic;  
